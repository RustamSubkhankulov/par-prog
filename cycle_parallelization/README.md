### Распараллеливание циклов

#### Условия Бернстейна

Пусть в программе имеются два оператора _S1_ и _S2_, непосредственно динамически следующих друг за другом. Пусть _W(S)_ – набор выходных переменных оператора _S_, а _R(S)_ – набор его входных переменных. Тогда возможность их одновременного выполнения различными исполнителями в параллельной системе можно определить с помощью *условий Бернстайна*.

Если для операторов _S1_ и _S2_, непосредственно динамически следующих друг за другом, выполнено:
  - пересечение _W(S1)_ и _W(S2)_ пусто;
  - пересечение _W(S1)_ и _R(S2)_ пусто;
  - пересечение _R(S1)_ и _W(S2)_ пусто;
то они могут быть исполнены параллельно. 

#### Анализ зависимостей в простых циклах

Во многих программах, связанных с математическим моделированием, приходится практически одинаковым образом обрабатывать большие массивы данных. Ввиду этого особый интерес представляет анализ существующих последовательных программ на параллелизм по данным. Распараллеливание по данным предполагает разделение массивов на зоны, каждая из которых обрабатывается отдельным исполнителем, — так называемые *зоны ответственности исполнителей*. Подобные вычисления обычно реализуется в последовательном коде с помощью операторов цикла. В работе рассматривается способ определения наличия зависимостей по данным для циклов, работающих с массивами, и влияние этих зависимостей на возможность параллельного выполнения циклов. 

Пусть тело цикла состоит из двух операторов _S1_ и _S2_, в наборы входных и/или выходных данных которых входит обращение к элементам одного и того же одномерного массива данных ``A``.
```
for (int i=0; i<i_fin; ++i) {
  S1: ...(A[f(i)])...
  S2: ... A[g(i)] ...
} 
```

Здесь ``f(i)`` и ``g(i)`` — некоторые целочисленные функции целого переменного. Для простоты будем считать, что индекс массива ``A`` может принимать любое целое значение. Нашей основной задачей является выяснение того, можно ли разбить итерационное пространство такого цикла — целочисленный отрезок ``[1, i_fin]`` — на зоны ответственности для параллельного выполнения. Вспомним, что на самом деле оператор цикла — это просто форма сокращения исходного текста программы. Если убрать это сокращение и развернуть цикл, то получим: 

```
S1,1: ...(A[f(1)])...
S2,1: ... A[g(1)] ...
S1,2: ...(A[f(2)])...
S2,2: ... A[g(2)] ...
...
S1,i_fin: ...(A[f(i_fin)])...
S2,i_fin: ... A[g(i_fin)] ...
```

В такой развернутой последовательности следующих друг за другом операторов можно провести анализ их совокупности на зависимость по данным. Будем полагать, что для одного оператора в теле цикла обращение к элементу массива A входит в набор входных переменных, а для другого — в набор выходных элементов. 

Без ограничения общности получаем цикл:
```
for (int i=0; i<i_fin; ++i) {
  S1: A[f(i)] = ...
  S2: ... = ...A[g(i)]...
}
```

Легко видеть, что условия Бернстайна могут быть нарушены в том случае, если существуют значения итерационной переменной ``i`` $\lambda$ и $\kappa$, ``1`` ≤ $\lambda$ ≤ ``i_fin``, ``1`` ≤ $\kappa$ ≤ ``i_fin`` такие, что f($\lambda$) = g($\kappa$). Чтобы узнать существуют ли такие значения, нужно решить приведенное уравнение при указанных ограничениях в целых числах. В общем случае определить, имеет ли уравнение решения, и найти их алгоритмически невозможно. 

В простых случаях, например, когда ``f`` и ``g`` — линейные функции, определить, существует ли решение, и каково оно, конечно, возможно, но в общем случае — нет. Если решения не существует, то все операторы развернутого цикла независимы друг от друга и могут быть выполнены одновременно различными исполнителями, скажем, каждая итерация цикла — на своем исполнителе. 

Пусть решение существует, и мы нашли соответствующие $\lambda$ и $\kappa$. Условия Бернстайна нарушены — между операторами есть зависимость. В этом случае оператор _S1_ (где элемент массива ``A`` — выходная переменная) называют *источником* (*source*) зависимости, а оператор _S2_ (где элемент массива ``A`` — входная переменная) называют *стоком* (*sink*) зависимости. Вычислим величину _D_ = $\lambda$ − $\kappa$ (из итерации стока вычитаем итерацию источника). Эту величину принято называть *расстоянием зависимости цикла*. 

Расстояние зависимости играет важную роль при анализе цикла на параллельность. Его значение позволяет определять тип возникающей зависимости по данным и возможность разбиения итерационного пространства на зоны ответственности для параллельного исполнения. 

1. Если расстояние зависимости _D_ < 0, то между операторами тела цикла существует *антизависимость*. Цикл может быть распараллелен так, что каждая итерация будет выполняться отдельным исполнителем, если перед началом выполнения итераций продублировать необходимые входные данные на исполнителях. 
2. Если расстояние зависимости _D_ > 0, то между операторами тела цикла существует *потоковая зависимость*. При _D_ > 1 цикл может быть распараллелен не более чем на D исполнителях. 
3. Если расстояние зависимости _D_ = 0, то тип зависимости между операторами тела цикла в общем случае не определен. Цикл может быть распараллелен так, что каждая итерация будет выполняться отдельным исполнителем. 

#### Анализ зависимостей во вложенных циклах

В современных научных исследованиях часто рассматриваются задачи, имеющие более одного измерения. При построении математических моделей таких задач приходится использовать многомерные массивы данных, а для их обработки в программах, реализующих построенные модели, — применять вложенные циклы. Нам необходимо уметь применять к подобным программным конструкциям аппарат анализа зависимостей по данным для возможного распараллеливания последовательного кода.

Рассмотрим нормализованный цикл:
```
for (int j1=0; j1<u1; ++j1) {
  for (int j2=0; j2<u2; ++j2) {
    ...
      for (int jn=0; jn<un; ++jn) {
      ...
      }
  }
} 
```

В таких циклах конкретная итерация определяется совокупностью значений всех счетчиков ``j1``, ``j2``, ..., ``jn``. Будем рассматривать их набор как n-мерный вектор _J_ = (``j1``, ``j2``, ..., ``jn``) и назовем его *итерационным вектором*. Множество всех допустимых значений итерационных векторов образует *итерационное пространство цикла*.

В этом пространстве между векторами можно ввести отношения порядка. Будем говорить, что:
  - _I_ = _J_, если ∀k, 1 ≤ k ≤ n, ``ik`` = ``jk``;
  - _I_ < _J_ в том случае, когда ∃s, 1 ≤ s ≤ n, такое что ∀k, 1 ≤ k < s, ``ik`` = jk, а ``is`` < ``js``. 

Как и в случае с одномерным циклом предположим, что тело цикла состоит из двух операторов _S1_ и _S2_, в наборы входных и/или выходных данных которых входит обращение к элементам одного и того же массива данных ``A`` с размерностью, совпадающей с количеством уровней вложенностей цикла. Пусть индексы массива могут принимать произвольные целочисленные значения. При этом для простоты допустим, что для оператора _S1_ элемент массива ``A`` принадлежит к _выходным_ переменным оператора, а для оператора _S2_ — к _входным_ переменным. Тогда можно представить цикл в виде:

```
for (int j1=0; j1<j_fin1; ++j1) {
  for (int j2=0; j2<j_fin2; ++j2) {
    ...
      for (int jn=0; jn<i_finn; ++jn) {
        S1: A[f1(J), ..., fn(J)] = ...
        S2: ... = ... A[g1(J),...,gn(J)] ...
      }
  }
} 
```

Здесь функции ``fk(J)`` и ``gk(J)``, 1 ≤ k ≤ n, есть целочисленные функции от n целых переменных. Задачей является выяснение возможности разбиения итерационного пространства такого цикла на _зоны ответственности_ для параллельного выполнения. 

Понятно, что условия Бернстайна нарушаются. Зависимость возникает, если имеет решение система уравнений _F(K) = G(Λ)_, где _F_ — вектор-функция (``f1``, ..., ``fn``), а _G_ — вектор функция (``g1``, ..., ``gn``). 

Введем для цикла понятие *вектора расстояний зависимости* (или просто *вектора расстояний*) следующим образом: _D_ = _Λ_ − _K_ (из вектора итераций, соответствующего итерации стока зависимости, вычитаем вектор итерации, соответствующий итерации источника зависимости). 

Определить тип существующей зависимости по данным и возможность распараллеливания цикла по виду вектора расстояний не так просто. Поэтому вводится понятие *вектора направлений для цикла*. Компоненты вектора направлений _d_ (а это — символьный вектор) определяются следующим образом:
  - _di_ = „=“, _Di_ = 0;
  - _di_ = „>“, _Di_ < 0;
  - _di_ = „<“, _Di_ > 0. 

1. Если многомерный цикл имеет вектор направлений _d_ = („=“, ..., „=“), то цикл может быть распараллелен по произвольному количеству индексов без всяких ограничений. При этом циклы, соответствующие различным уровням вложенности первоначальной конструкции, можно безопасно менять местами.
2. Пусть многомерный цикл имеет вектор направлений _d_, в состав которого входят только элементы «>» и «=». Такой цикл может быть распараллелен без всяких ограничений по любому количеству индексов, соответствующих компонентам «=» в векторе направлений. Распараллеливание по индексам, соответствующим компонентам «>» в векторе направлений, возможно при дублировании необходимых входных данных. Перед распараллеливанием циклы, соответствующие различным уровням вложенности первоначальной конструкции, можно безопасно менять местами. 
3. Пусть многомерный цикл имеет вектор направлений d, в состав которого входят только элементы „<“ и „=“. Такой цикл может быть распараллелен без всяких ограничений по любому количеству индексов, соответствующих компонентам „=“ в векторе направлений. Распараллеливание по индексам, соответствующим компонентам „<“ в векторе направлений, проблематично. Перед распараллеливанием циклы, соответствующие различным уровням вложенности первоначальной конструкции, можно безопасно менять местами. 
4. Пусть для некоторого многомерного цикла определен вектор направлений _d_. *Истинная зависимость* в цикле существует тогда и только тогда, когда крайний левый элемент вектора направлений, отличный от „=“, есть „<“. 
5. Для произвольного цикла возможно распараллеливание по любому индексу, соответствующему компоненту „=“ в векторе направлений. Уровень вложенности, соответствующий этому компоненту, можно поменять местами с любым соседним уровнем вложенности с сохранением результата вычислений. Два соседних уровня вложенности, которым соответствуют _одинаковые_ компоненты вектора направлений, также можно поменять местами. Если в цикле существует _антизависимость_, то распараллеливание возможно по произвольному количеству индексов при дублировании необходимых входных данных. Распараллеливание для циклов с истинной зависимостью может быть проблематично. 

Естественно, что для цикла, в котором зависимости возникают по элементам не одного, а нескольких массивов, решение о возможности распараллеливания принимается по результатам анализа всей _совокупности_ зависимостей. 

#### Практическая часть

Основным заданием данной лабораторной работы является разработка и исследование параллельных программ, созданных на основе существующих заготовок последовательных программ. Полученные результаты требуется сравнить, а также изобразить графически для каждой из реализаций зависимость коэффициента ускорения программы от количества используемых исполнителей. 

#### Задание первое 

Програмнный код располагается в _src/task01.cpp_.

Опуская некоторые детали, последовательная версия программы выглядит следующий образом:
```cpp
#include <cmath>
/* includes */

namespace
{
/* Array dimensions. */
const int Isize = 40000;
const int Jsize = 40000;
} /* anonymous namespace */

int main()
{
  using column = double[Jsize];
  auto a       = new column[Isize];

  /* Preparation - fill array with some data. */
  for (int i = 0; i < Isize; i++)
  {
    for (int j = 0; j < Jsize; j++)
    {
      a[i][j] = 10 * i + j;
    }
  }

  /* Time mesurement starts. */

  /* Main computational cycle. */
  for (int i = 0; i < Isize; i++)
  {
    for (int j = 0; j < Jsize; j++)
    {
      a[i][j] = sin(2 * a[i][j]);
    }
  }

  /* Time mesurement stops. Results are written to file. */

  delete[] a;
}
```

Вектор расстояний зависимости - _D_ = (0; 0)
Вектор направлений - _d_ = ("="; "="). Цикл может быть распараллелен по произвольному количеству индексов без всяких ограничений.

#### Паралельная версия программы с использованием технологии *OpenMP*.

В качестве одного из вариантов реализации параллельной версии программы была использована технология _OpenMP_. Для распараллеливания достаточно воспользоваться командами препроцессора, как приведено ниже. 

```cpp
/* Main computational cycle. */
#pragma omp parallel default(none) shared(a, Isize, Jsize)
#pragma omp for schedule(static)
for (int i = 0; i < Isize; i++)
{
  for (int j = 0; j < Jsize; j++)
  {
    a[i][j] = sin(2 * a[i][j]);
  }
}
```

Зависимость времени вычисления от количества исполнителей приведена в таблице:

|           | 1    | 2   | 4   | 8   | 16  | 32  | 64  | 128 | 256 | 512 | 1024 |
|-----------|------|-----|-----|-----|-----|-----|-----|-----|-----|-----|------|
| time      | 11,2 | 6,4 | 4,5 | 3,3 | 3,6 | 3,3 | 3,3 | 3,5 | 3,4 | 3,3 | 3,4  |

График зависимости времени исполнения от количества исполнителей:

<img src="https://github.com/RustamSubkhankulov/par-prog/blob/main/cycle_parallelization/images/graph01OMP_T.png" alt="task01_OMP time(p)" width="700"/>

График зависимости величины ускорения от количества исполнителей:

<img src="https://github.com/RustamSubkhankulov/par-prog/blob/main/cycle_parallelization/images/graph01OMP_S.png" alt="task01_OMP S(p)" width="700"/>

График зависимости величины эффективности от количества исполнителей:

<img src="https://github.com/RustamSubkhankulov/par-prog/blob/main/cycle_parallelization/images/graph01OMP_E.png" alt="task01_OMP E(p)" width="700"/>

Можем видеть, что:
  - Максимальное ускорение достигается уже при использовании 8-ми исполнителей, и далее не увеличивается.
  - Пик эффективности достигается при использовании 2-ух исполнителей, не считая однопоточной версии программы. С увеличением числа исполнителей эффективность падает, потому как величина ускорения остается примерно постоянной, а количество исполнителей - растет.

#### Паралельная версия программы с использованием технологии *MPI*.

Зависимость времени вычисления от количества исполнителей приведена в таблице:

|           | 1    | 2    | 3    | 4    | 5    | 6    | 8    |
|-----------|------|------|------|------|------|------|------|
| time      | 1,82 | 1,23 | 1,04 | 0,92 | 0,97 | 1,04 | 1,03 |

График зависимости времени исполнения от количества исполнителей:

<img src="https://github.com/RustamSubkhankulov/par-prog/blob/main/cycle_parallelization/images/graph01MPI_T.png" alt="task01_MPI time(p)" width="700"/>

График зависимости величины ускорения от количества исполнителей:

<img src="https://github.com/RustamSubkhankulov/par-prog/blob/main/cycle_parallelization/images/graph01MPI_S.png" alt="task01_MPI S(p)" width="700"/>

График зависимости величины эффективности от количества исполнителей:

<img src="https://github.com/RustamSubkhankulov/par-prog/blob/main/cycle_parallelization/images/graph01MPI_E.png" alt="task01_MPI E(p)" width="700"/>

Можем видеть, что:
  - Максимальное ускорение достигается уже при использовании 4-x исполнителей, и далее падает. Это связано с тем, что ускорение от распараллеливания вычислений уже не покрывает накладные расходы на передачу сообщений между процессами в коммуникаторе.
  - Пик эффективности также достигается при использовании 2-ух исполнителей, не считая однопоточной версии программы. С увеличением числа процессов эффективность падает из-за растущих накладных расходов на пересылку данных между ними.
